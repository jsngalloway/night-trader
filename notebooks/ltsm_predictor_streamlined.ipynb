{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, optimizers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "register_matplotlib_converters()\n",
    "sns.set(style=\"darkgrid\", font_scale=1.5)\n",
    "\n",
    "LENGTH = 50\n",
    "SUBSAMPLING = 20 #once every 20 seconds predict"
   ]
  },
  {
   "source": [
    "# Train Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessTestingData(data, length):\n",
    "    hist = []\n",
    "    target = []\n",
    "\n",
    "    for i in range(len(data)-length):\n",
    "        x = data[i:i+length]\n",
    "        y = data[i+length]\n",
    "        hist.append(x)\n",
    "        target.append(y)\n",
    "    \n",
    "    # Convert into numpy arrays and shape correctly (len(dataset), length) and (len(dataset), 1) respectivly\n",
    "    hist = np.array(hist)\n",
    "    target = np.array(target)\n",
    "    target = target.reshape(-1,1)\n",
    "\n",
    "    #Reshape the input into (len(dataset), length, 1)\n",
    "    hist = hist.reshape((len(hist), length, 1))\n",
    "\n",
    "    return(hist, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(datasets, length, model=None, quiet=False):\n",
    "    for dataset in datasets:\n",
    "        X_train, y_train = preprocessTestingData(dataset, length)\n",
    "\n",
    "        if not model:\n",
    "            # Create model and compile\n",
    "            model = tf.keras.Sequential()\n",
    "            model.add(layers.LSTM(units=32, return_sequences=True, input_shape=(length,1), dropout=0.2))\n",
    "            model.add(layers.LSTM(units=32, return_sequences=True, dropout=0.2))\n",
    "            model.add(layers.LSTM(units=32, dropout=0.2))\n",
    "            model.add(layers.Dense(units=1))\n",
    "            optimizer = optimizers.Adam()\n",
    "            model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "        # Perform training\n",
    "        output = 1\n",
    "        if quiet:\n",
    "            output = 0\n",
    "        history = model.fit(X_train, y_train, epochs=6, batch_size=32, verbose=output)\n",
    "\n",
    "        # Show loss\n",
    "        if not quiet:\n",
    "            loss = history.history['loss']\n",
    "            epoch_count = range(1, len(loss) + 1)\n",
    "            plt.figure(figsize=(6,4))\n",
    "            plt.plot(epoch_count, loss, 'r--')\n",
    "            plt.legend(['Training Loss'])\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.show()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaleData(paths):\n",
    "    scaler = MinMaxScaler()\n",
    "    datasets = []\n",
    "    for path in paths:\n",
    "        # perform partial fits on all datasets\n",
    "        datasets.append(pd.read_csv(path)[['price']][::SUBSAMPLING]) # TODO remove, 120 subsample for every two minues\n",
    "        scaler = scaler.partial_fit(datasets[-1])\n",
    "    for i in range(len(datasets)):\n",
    "        # once all partial fits have been performed, transform every file\n",
    "        datasets[i] = scaler.transform(datasets[i])\n",
    "    return (datasets, scaler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\"../data/MorningTest.csv\", \"../data/MorningTest2.csv\", \"../data/MorningTest5.csv\", \"../data/MorningTest6.csv\", \"../data/MorningTest7.csv\", \"../data/MorningTest8.csv\"]\n",
    "\n",
    "datasets, scaler = scaleData(paths)\n",
    "\n",
    "model = trainModel(datasets, LENGTH)"
   ]
  },
  {
   "source": [
    "# Test Model\n",
    "## Evaluation Helpers"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_sample(arr1, arr2, sub):\n",
    "    return (arr1[::sub], arr2[::sub])\n",
    "\n",
    "def evaluate_model(real_data, predicted_data, inherent_loss=2):\n",
    "    real_data = real_data.reshape(len(real_data))\n",
    "    predicted_data = predicted_data.reshape(len(predicted_data))\n",
    "\n",
    "    real_diff = np.diff(real_data)\n",
    "    predicted_diff = np.diff(predicted_data)\n",
    "\n",
    "    correct_slopes = 0\n",
    "    profit = 0\n",
    "    for i in range(len(real_data)-1):\n",
    "        if np.sign(real_diff[i]) == np.sign(predicted_diff[i]):\n",
    "            correct_slopes = correct_slopes + 1\n",
    "            \n",
    "            # If we have a positive slope calculate profit\n",
    "            if real_diff[i] > 0:\n",
    "                # we subtract inherent_loss due to the limit market mechanics\n",
    "                revenue = (real_data[i+1] - real_data[i]) - inherent_loss\n",
    "                if revenue > 0:\n",
    "                    # print(f\"Found a profit where current value is {real_data[i+1]} last was {real_data[i]} net {revenue}\")\n",
    "                    profit = profit + revenue\n",
    "\n",
    "        else:\n",
    "            # We guessed wrong\n",
    "            if predicted_diff[i] > 0:\n",
    "                # we would have bought\n",
    "                revenue = (real_data[i+1] - real_data[i]) - inherent_loss\n",
    "                # print(f\"Selling at a loss of {revenue}\")\n",
    "                profit = profit + revenue\n",
    "\n",
    "    return (correct_slopes, profit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model_on_dataset(actual, prediction, subsampling, inherent_loss):\n",
    "    # Subsample the test points, this seems to increase accuracy\n",
    "    real_subbed, pred_subbed = sub_sample(actual, prediction, subsampling)\n",
    "\n",
    "    # Determine the number of cases in which we predicted a correct increase\n",
    "    correct_slopes, profit = evaluate_model(real_subbed, pred_subbed, inherent_loss)\n",
    "\n",
    "    print(f\"Found {correct_slopes} out of {len(real_subbed)-1}\")\n",
    "    precent_success = (correct_slopes/(len(real_subbed)-1)) * 100\n",
    "    print(f\"{precent_success}%\")\n",
    "    print(\"Profit:\", profit)\n",
    "    return profit"
   ]
  },
  {
   "source": [
    "## Test Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testModel(model, path_to_testing_dataset, quiet=False):\n",
    "\n",
    "    datasets, scaler = scaleData([path_to_testing_dataset])\n",
    "\n",
    "    hist, actual = preprocessTestingData(datasets[0], LENGTH)\n",
    "\n",
    "    pred = model.predict(hist)\n",
    "\n",
    "    pred_transformed = scaler.inverse_transform(pred)\n",
    "    actual_transformed = scaler.inverse_transform(actual)\n",
    "\n",
    "    if not quiet:\n",
    "        plt.figure(figsize=(12,8))\n",
    "        plt.plot(actual_transformed, color='blue', label='Real')\n",
    "        plt.plot(pred_transformed, color='red', label='Prediction')\n",
    "        plt.title('ETH Price Prediction')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    return eval_model_on_dataset(actual=actual_transformed, prediction=pred_transformed, subsampling=1, inherent_loss=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "testModel(model, \"../data/MorningTest4.csv\")"
   ]
  },
  {
   "source": [
    "# Single Prediction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example, if we just want to predict the next timestep in the dataset we can prepare it as such:\n",
    "\n",
    "# 1. get the [length] last points from the data set since that's what we care about\n",
    "length = LENGTH\n",
    "most_recent_period = pd.read_csv('../data/MorningTest2.csv')[['price']].tail(length)\n",
    "\n",
    "# 2. convert to numpy array \n",
    "most_recent_period = np.array(most_recent_period)\n",
    "\n",
    "# 3. normalize data\n",
    "scaler = MinMaxScaler()\n",
    "most_recent_period_scaled = scaler.fit_transform(most_recent_period)\n",
    "\n",
    "# 4. reshape to the 3D tensor we expected (1, length, 1)\n",
    "most_recent_period_scaled_shaped = most_recent_period_scaled.reshape((1, length, 1))\n",
    "\n",
    "# 5. Predict\n",
    "prediction = model.predict(most_recent_period_scaled_shaped)\n",
    "\n",
    "# 6. Un-normalize the data\n",
    "result = scaler.inverse_transform(prediction)\n",
    "\n",
    "print(f\"${result[0][0]}\")"
   ]
  },
  {
   "source": [
    "# Prediction Success Evaluation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pink = models.load_model(\"my_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profits = []\n",
    "for length in np.arange(5, 360, 5):\n",
    "    for sub in np.arange(10, 480, 5):\n",
    "        try:\n",
    "            LENGTH = length\n",
    "            SUBSAMPLING = sub\n",
    "            model = trainModel(datasets, LENGTH, quiet=True)\n",
    "            profit = testModel(model, \"../data/MorningTest4.csv\", quiet=True)\n",
    "            profits.append((profit, length, sub))\n",
    "            print((profit, length, sub))\n",
    "        except:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}