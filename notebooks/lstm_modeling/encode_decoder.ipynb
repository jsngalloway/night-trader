{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, optimizers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "register_matplotlib_converters()\n",
    "sns.set(style=\"darkgrid\", font_scale=1.5)\n",
    "\n",
    "LENGTH = 500\n",
    "LOOK_AHEAD_LENGTH = 40"
   ]
  },
  {
   "source": [
    "# Train Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shapeData(data, length, look_ahead_length):\n",
    "    \"\"\"\n",
    "    Returns a tuple of hist and target, the two datasets needed for training/testing\n",
    "    params:\n",
    "        data                a numpy array of the data: 1D\n",
    "        length              an int, how many past frames should be used in prediction\n",
    "        look_ahead_length   how many future frames ahead to predict each time\n",
    "    \"\"\"\n",
    "    hist = []\n",
    "    target = []\n",
    "\n",
    "    for i in range(len(data)-length-look_ahead_length):\n",
    "        x = data[i:i+length]\n",
    "        y = data[i+length:i+length+look_ahead_length]\n",
    "        hist.append(x)\n",
    "        target.append(y)\n",
    "    \n",
    "    # Convert into numpy arrays and shape correctly (len(dataset), length) and (len(dataset), 1) respectivly\n",
    "    hist = np.array(hist)\n",
    "    target = np.array(target)\n",
    "\n",
    "    # print(hist[0][length-1])\n",
    "    # print(target[0][0])\n",
    "    # print(data[length-1:length+1])\n",
    "\n",
    "    # print(hist[100][length-1])\n",
    "    # print(target[100][0])\n",
    "    # print(data[100+length-1:100+length+1])\n",
    "\n",
    "    # print(\"Target 0\", target[0])\n",
    "    # print(\"Target 0 reshape\", target.reshape(-1,1))\n",
    "    # print(\"Target 0 reshape size\", target.reshape(-1,1).shape)\n",
    "    # target = target.reshape(-1,1)\n",
    "\n",
    "    #Reshape the input into (len(dataset), length, 1)\n",
    "    hist = hist.reshape((len(hist), length, 1))\n",
    "\n",
    "    return(hist, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(datasets, length, model=None, quiet=False):\n",
    "    for dataset in datasets:\n",
    "        X_train, y_train = shapeData(dataset, length, LOOK_AHEAD_LENGTH)\n",
    "\n",
    "        if not model:\n",
    "            # Create model and compile if not already passed a model\n",
    "            model = tf.keras.Sequential()\n",
    "            model.add(layers.LSTM(units=64, input_shape=(length,1), dropout=0.05, activation='relu'))\n",
    "            model.add(layers.RepeatVector(LOOK_AHEAD_LENGTH))\n",
    "            model.add(layers.LSTM(units=64, return_sequences=True, dropout=0.05, activation='relu'))\n",
    "            model.add(layers.TimeDistributed(layers.Dense(64, activation='relu')))\n",
    "            model.add(layers.TimeDistributed(layers.Dense(1)))\n",
    "            model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "            print(model.summary())\n",
    "\n",
    "        # Perform training\n",
    "        output = 1\n",
    "        if quiet:\n",
    "            output = 0\n",
    "        history = model.fit(X_train, y_train, epochs=10, batch_size=100, verbose=output, shuffle=False)\n",
    "\n",
    "        # Show loss\n",
    "        if not quiet:\n",
    "            loss = history.history['loss']\n",
    "            epoch_count = range(1, len(loss) + 1)\n",
    "            plt.figure(figsize=(6,4))\n",
    "            plt.plot(epoch_count, loss, 'r--')\n",
    "            plt.legend(['Training Loss'])\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.show()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaleData(paths):\n",
    "    scaler = MinMaxScaler()\n",
    "    datasets = []\n",
    "    for path in paths:\n",
    "        # perform partial fits on all datasets\n",
    "        \n",
    "        new_df = pd.DataFrame()\n",
    "        new_df[\"price\"] = pd.read_csv(path)[[\"high_price\",\"low_price\"]].mean(axis=1)\n",
    "        \n",
    "        datasets.append(new_df)\n",
    "\n",
    "        scaler = scaler.partial_fit(datasets[-1])\n",
    "    for i in range(len(datasets)):\n",
    "        # once all partial fits have been performed, transform every file\n",
    "        datasets[i] = scaler.transform(datasets[i])\n",
    "    return (datasets, scaler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(interest_df, alt_dataframe):\n",
    "    # Use ETH and LTC\n",
    "    return_df = pd.DataFrame()\n",
    "    return_df[\"price\"] = raw_dataframe[[\"high_price\",\"low_price\"]].mean(axis=1).tail(15000)\n",
    "    return_df[\"ema75\"] = return_df[\"price\"].ewm(span=75, adjust=False).mean()\n",
    "    return_df[\"ema15\"] = return_df[\"price\"].ewm(span=15, adjust=False).mean()\n",
    "    return_df[\"ema5\"] = return_df[\"price\"].ewm(span=5, adjust=False).mean()\n",
    "    return_df[\"related_price\"] = alt_dataframe[[\"high_price\",\"low_price\"]].mean(axis=1).tail(15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_6\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nlstm_12 (LSTM)               (None, 200)               161600    \n_________________________________________________________________\nrepeat_vector_6 (RepeatVecto (None, 3, 200)            0         \n_________________________________________________________________\nlstm_13 (LSTM)               (None, 3, 200)            320800    \n_________________________________________________________________\ntime_distributed_12 (TimeDis (None, 3, 100)            20100     \n_________________________________________________________________\ntime_distributed_13 (TimeDis (None, 3, 1)              101       \n=================================================================\nTotal params: 502,601\nTrainable params: 502,601\nNon-trainable params: 0\n_________________________________________________________________\nNone\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 22067\n  y sizes: 66201\nMake sure all arrays contain the same number of samples.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-afa77dbf593a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLENGTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-48-95a8abb53fff>\u001b[0m in \u001b[0;36mtrainModel\u001b[0;34m(datasets, length, model, quiet)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mquiet\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# Show loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1048\u001b[0m          \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRespectCompiledTrainableState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m       \u001b[0;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m       data_handler = data_adapter.DataHandler(\n\u001b[0m\u001b[1;32m   1051\u001b[0m           \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m           \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m     self._adapter = adapter_cls(\n\u001b[0m\u001b[1;32m   1101\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m     \u001b[0m_check_data_cardinality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;31m# If batch_size is not passed but steps is, calculate from the input data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_check_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1527\u001b[0m           label, \", \".join(str(i.shape[0]) for i in nest.flatten(single_data)))\n\u001b[1;32m   1528\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"Make sure all arrays contain the same number of samples.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1529\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 22067\n  y sizes: 66201\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "paths = [\"../../data/ETH.csv\"]\n",
    "\n",
    "datasets, scaler = scaleData(paths)\n",
    "\n",
    "# X_train, y_train = preprocessTestingData(datasets[0], LENGTH, LOOK_AHEAD_LENGTH)\n",
    "\n",
    "\n",
    "model = trainModel(datasets, LENGTH)"
   ]
  },
  {
   "source": [
    "# Test Model\n",
    "## Evaluation Helpers"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_sample(arr1, arr2):\n",
    "    return (arr1, arr2)\n",
    "\n",
    "def evaluate_model(real_data, predicted_data, inherent_loss):\n",
    "    real_data = real_data.reshape(len(real_data))\n",
    "    predicted_data = predicted_data.reshape(len(predicted_data))\n",
    "\n",
    "    real_diff = np.diff(real_data)\n",
    "    predicted_diff = np.diff(predicted_data)\n",
    "\n",
    "    correct_slopes = 0\n",
    "    profit = 0\n",
    "    for i in range(len(real_data)-1-LOOK_AHEAD_LENGTH):\n",
    "        if np.sign(real_diff[i+LOOK_AHEAD_LENGTH-1]) == np.sign(predicted_diff[i]):\n",
    "            correct_slopes = correct_slopes + 1\n",
    "            \n",
    "            # If we have a positive slope calculate profit\n",
    "            if predicted_diff[i] > 1.75:\n",
    "                # we subtract inherent_loss due to the limit market mechanics\n",
    "                revenue = (real_data[i+1] - real_data[i]) - inherent_loss\n",
    "                if revenue > 0:\n",
    "                    # print(f\"Found a profit where current value is {real_data[i+1]} last was {real_data[i]} net {revenue}\")\n",
    "                    profit = profit + revenue\n",
    "\n",
    "        else:\n",
    "            # We guessed wrong\n",
    "            if predicted_diff[i] > 0:\n",
    "                # we would have bought\n",
    "                revenue = (real_data[i+1] - real_data[i]) - inherent_loss\n",
    "                # print(f\"Selling at a loss of {revenue}\")\n",
    "                profit = profit + revenue\n",
    "\n",
    "    return (correct_slopes, profit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model_on_dataset(actual, prediction, inherent_loss):\n",
    "    # Subsample the test points, this seems to increase accuracy\n",
    "    real_subbed, pred_subbed = sub_sample(actual, prediction)\n",
    "\n",
    "    # Determine the number of cases in which we predicted a correct increase\n",
    "    correct_slopes, profit = evaluate_model(real_subbed, pred_subbed, inherent_loss)\n",
    "\n",
    "    print(f\"Found {correct_slopes} out of {len(real_subbed)-1}\")\n",
    "    precent_success = (correct_slopes/(len(real_subbed)-1)) * 100\n",
    "    print(f\"{precent_success}%\")\n",
    "    print(\"Profit:\", profit)\n",
    "    return profit"
   ]
  },
  {
   "source": [
    "## Test Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testModel(model, path_to_testing_dataset, quiet=False):\n",
    "\n",
    "    datasets, scaler = scaleData([path_to_testing_dataset])\n",
    "\n",
    "    hist, actual = shapeData(datasets[0], LENGTH, LOOK_AHEAD_LENGTH)\n",
    "\n",
    "    pred = model.predict(hist)\n",
    "\n",
    "    print(pred)\n",
    "    # for p in pred:\n",
    "    # pred_transformed.append(scaler.inverse_transform(p))\n",
    "    pred_transformed = scaler.inverse_transform(pred[0])\n",
    "    actual_transformed = scaler.inverse_transform(actual[0])\n",
    "    hist_transformed = scaler.inverse_transform(hist[0])\n",
    "\n",
    "    # print(hist[0])\n",
    "    if not quiet:\n",
    "        plt.figure(figsize=(12,8))\n",
    "        plt.plot(hist_transformed, color='blue', label='History')\n",
    "        plt.plot(np.arange(40,50),pred_transformed, color='red', label='Prediction')\n",
    "        plt.plot(np.arange(40,50),actual_transformed, color='purple', label='Actual')\n",
    "        plt.title('ETH Price Prediction')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    return #eval_model_on_dataset(actual=actual_transformed, prediction=pred_transformed, inherent_loss=1.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'testModel' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-0bd6c26cf2ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtestModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"../../data/ETH.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'testModel' is not defined"
     ]
    }
   ],
   "source": [
    "testModel(model, \"../../data/ETH.csv\")"
   ]
  },
  {
   "source": [
    "# Single Prediction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"257.308906pt\" version=\"1.1\" viewBox=\"0 0 400.6925 257.308906\" width=\"400.6925pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-02-05T11:54:26.930146</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.3, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 257.308906 \nL 400.6925 257.308906 \nL 400.6925 0 \nL 0 0 \nz\n\" style=\"fill:#ffffff;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 58.6925 224.64 \nL 393.4925 224.64 \nL 393.4925 7.2 \nL 58.6925 7.2 \nz\n\" style=\"fill:#eaeaf2;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path clip-path=\"url(#pcada54abc7)\" d=\"M 73.910682 224.64 \nL 73.910682 7.2 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g style=\"fill:#262626;\" transform=\"translate(68.661619 246.677422)scale(0.165 -0.165)\">\n       <defs>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <path clip-path=\"url(#pcada54abc7)\" d=\"M 130.378889 224.64 \nL 130.378889 7.2 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"text_2\">\n      <!-- 100 -->\n      <g style=\"fill:#262626;\" transform=\"translate(114.631701 246.677422)scale(0.165 -0.165)\">\n       <defs>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <path clip-path=\"url(#pcada54abc7)\" d=\"M 186.847096 224.64 \nL 186.847096 7.2 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"text_3\">\n      <!-- 200 -->\n      <g style=\"fill:#262626;\" transform=\"translate(171.099909 246.677422)scale(0.165 -0.165)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <path clip-path=\"url(#pcada54abc7)\" d=\"M 243.315303 224.64 \nL 243.315303 7.2 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"text_4\">\n      <!-- 300 -->\n      <g style=\"fill:#262626;\" transform=\"translate(227.568116 246.677422)scale(0.165 -0.165)\">\n       <defs>\n        <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <path clip-path=\"url(#pcada54abc7)\" d=\"M 299.78351 224.64 \nL 299.78351 7.2 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"text_5\">\n      <!-- 400 -->\n      <g style=\"fill:#262626;\" transform=\"translate(284.036323 246.677422)scale(0.165 -0.165)\">\n       <defs>\n        <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <path clip-path=\"url(#pcada54abc7)\" d=\"M 356.251717 224.64 \nL 356.251717 7.2 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"text_6\">\n      <!-- 500 -->\n      <g style=\"fill:#262626;\" transform=\"translate(340.50453 246.677422)scale(0.165 -0.165)\">\n       <defs>\n        <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <path clip-path=\"url(#pcada54abc7)\" d=\"M 58.6925 219.942217 \nL 393.4925 219.942217 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"text_7\">\n      <!-- 1720 -->\n      <g style=\"fill:#262626;\" transform=\"translate(7.2 226.210928)scale(0.165 -0.165)\">\n       <defs>\n        <path d=\"M 8.203125 72.90625 \nL 55.078125 72.90625 \nL 55.078125 68.703125 \nL 28.609375 0 \nL 18.3125 0 \nL 43.21875 64.59375 \nL 8.203125 64.59375 \nz\n\" id=\"DejaVuSans-55\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <path clip-path=\"url(#pcada54abc7)\" d=\"M 58.6925 170.936641 \nL 393.4925 170.936641 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"text_8\">\n      <!-- 1730 -->\n      <g style=\"fill:#262626;\" transform=\"translate(7.2 177.205352)scale(0.165 -0.165)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <path clip-path=\"url(#pcada54abc7)\" d=\"M 58.6925 121.931066 \nL 393.4925 121.931066 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"text_9\">\n      <!-- 1740 -->\n      <g style=\"fill:#262626;\" transform=\"translate(7.2 128.199777)scale(0.165 -0.165)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <path clip-path=\"url(#pcada54abc7)\" d=\"M 58.6925 72.92549 \nL 393.4925 72.92549 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"text_10\">\n      <!-- 1750 -->\n      <g style=\"fill:#262626;\" transform=\"translate(7.2 79.194201)scale(0.165 -0.165)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <path clip-path=\"url(#pcada54abc7)\" d=\"M 58.6925 23.919914 \nL 393.4925 23.919914 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"text_11\">\n      <!-- 1760 -->\n      <g style=\"fill:#262626;\" transform=\"translate(7.2 30.188625)scale(0.165 -0.165)\">\n       <defs>\n        <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_12\">\n    <path clip-path=\"url(#pcada54abc7)\" d=\"M 73.910682 207.335533 \nL 74.475364 206.196153 \nL 75.040046 211.008733 \nL 75.604728 203.317075 \nL 76.16941 206.600449 \nL 76.734092 211.941008 \nL 77.298774 213.435678 \nL 77.863456 213.951285 \nL 78.428138 214.756364 \nL 78.99282 209.614292 \nL 79.557503 210.30037 \nL 80.686867 212.741688 \nL 81.251549 210.238241 \nL 81.816231 212.782338 \nL 82.380913 204.67489 \nL 82.945595 209.671109 \nL 83.510277 200.386611 \nL 84.074959 195.86653 \nL 84.639641 199.433384 \nL 85.204323 196.895647 \nL 85.769005 200.474901 \nL 86.898369 187.635291 \nL 87.463052 185.409453 \nL 88.027734 185.969102 \nL 88.592416 183.405186 \nL 89.157098 186.767091 \nL 89.72178 185.773079 \nL 90.286462 185.062498 \nL 90.851144 190.020559 \nL 91.415826 180.284455 \nL 91.980508 178.604674 \nL 92.54519 160.339186 \nL 93.109872 154.223135 \nL 93.674554 158.846973 \nL 94.239236 146.482859 \nL 94.803918 145.159708 \nL 95.368601 153.763015 \nL 95.933283 149.143732 \nL 96.497965 148.259311 \nL 97.062647 152.167506 \nL 97.627329 149.898785 \nL 98.192011 152.07367 \nL 98.756693 137.551593 \nL 99.321375 128.77601 \nL 99.886057 130.239135 \nL 100.450739 133.118561 \nL 101.015421 123.9893 \nL 101.580103 124.589618 \nL 102.144785 116.598639 \nL 102.709467 106.090013 \nL 103.27415 109.66742 \nL 103.838832 106.163522 \nL 104.403514 106.861851 \nL 105.532878 118.134221 \nL 106.09756 117.48381 \nL 106.662242 123.119451 \nL 107.226924 122.261853 \nL 107.791606 117.189776 \nL 108.356288 120.97815 \nL 108.92097 108.123745 \nL 109.485652 110.880308 \nL 110.050334 104.343273 \nL 110.615016 107.11913 \nL 111.179699 101.189456 \nL 111.744381 107.726574 \nL 112.309063 108.048286 \nL 112.873745 116.466944 \nL 113.438427 111.811414 \nL 114.003109 114.15143 \nL 114.567791 123.327724 \nL 115.697155 146.924821 \nL 116.261837 145.039008 \nL 116.826519 137.098291 \nL 117.391201 135.395759 \nL 117.955883 132.52538 \nL 119.085248 105.085399 \nL 119.64993 93.728357 \nL 120.214612 84.983559 \nL 120.779294 79.528991 \nL 121.343976 76.784679 \nL 121.908658 77.568768 \nL 123.038022 85.118048 \nL 123.602704 90.579749 \nL 124.167386 89.685397 \nL 124.732068 86.316263 \nL 125.29675 89.18309 \nL 125.861432 95.394546 \nL 126.426114 96.227641 \nL 126.990797 96.332168 \nL 127.555479 98.290788 \nL 128.684843 91.133948 \nL 129.249525 92.018481 \nL 129.814207 86.206001 \nL 130.378889 90.114196 \nL 131.508253 95.811094 \nL 132.072935 94.230664 \nL 132.637617 95.357792 \nL 133.202299 100.772908 \nL 133.766981 116.032482 \nL 134.331663 112.91404 \nL 134.896346 120.424144 \nL 135.461028 133.176468 \nL 136.02571 138.359425 \nL 137.155074 121.933077 \nL 137.719756 120.191368 \nL 138.284438 123.79301 \nL 138.84912 112.338224 \nL 139.413802 109.912448 \nL 139.978484 113.097811 \nL 140.543166 121.57009 \nL 141.107848 122.083598 \nL 141.67253 120.947862 \nL 142.237212 119.269943 \nL 142.801895 109.155189 \nL 143.366577 102.02255 \nL 143.931259 102.709498 \nL 144.495941 101.422232 \nL 145.060623 96.301149 \nL 145.625305 102.353338 \nL 146.189987 104.434345 \nL 146.754669 108.160499 \nL 147.319351 120.306043 \nL 147.884033 116.564955 \nL 148.448715 122.626599 \nL 149.013397 118.794709 \nL 150.142761 133.61462 \nL 150.707443 141.970109 \nL 151.272126 146.417005 \nL 151.836808 163.202111 \nL 152.40149 163.601715 \nL 152.966172 159.299983 \nL 153.530854 147.156686 \nL 154.095536 147.718495 \nL 154.660218 145.599761 \nL 155.2249 152.127417 \nL 155.789582 149.484451 \nL 156.354264 148.565596 \nL 156.918946 158.722002 \nL 157.483628 165.729799 \nL 158.04831 170.739632 \nL 158.612992 168.131072 \nL 159.177675 179.979956 \nL 159.742357 179.448224 \nL 160.307039 191.375475 \nL 160.871721 184.355078 \nL 161.436403 188.706261 \nL 162.001085 190.23405 \nL 162.565767 189.681274 \nL 163.130449 205.46263 \nL 163.695131 201.710822 \nL 164.259813 201.66337 \nL 164.824495 202.75614 \nL 165.953859 181.742371 \nL 166.518541 186.033718 \nL 167.083224 178.400859 \nL 167.647906 169.245949 \nL 168.212588 171.965758 \nL 168.77727 170.569099 \nL 169.341952 162.801716 \nL 169.906634 160.780236 \nL 170.471316 157.619376 \nL 171.035998 170.146995 \nL 171.60068 161.637833 \nL 172.165362 162.2259 \nL 172.730044 161.515319 \nL 173.294726 169.719605 \nL 173.859408 159.32232 \nL 174.42409 157.839901 \nL 174.988773 149.974506 \nL 175.553455 137.772118 \nL 176.118137 137.024783 \nL 176.682819 134.574504 \nL 177.247501 132.712292 \nL 177.812183 134.807281 \nL 178.376865 133.802666 \nL 178.941547 134.844035 \nL 179.506229 131.291131 \nL 180.070911 127.027645 \nL 180.635593 129.196142 \nL 181.200275 127.023473 \nL 181.764957 132.787386 \nL 182.329639 130.612685 \nL 182.894322 120.264876 \nL 183.459004 118.966228 \nL 184.023686 115.46233 \nL 184.588368 114.080568 \nL 185.15305 111.316328 \nL 185.717732 114.727246 \nL 186.282414 109.079353 \nL 186.847096 108.530273 \nL 187.411778 114.958738 \nL 187.97646 106.445304 \nL 189.105824 102.610617 \nL 189.670506 103.284444 \nL 190.235188 100.687149 \nL 190.799871 99.180227 \nL 191.364553 104.988672 \nL 191.929235 94.230664 \nL 192.493917 91.976407 \nL 193.058599 94.892239 \nL 194.187963 130.065991 \nL 194.752645 123.609507 \nL 195.882009 134.709269 \nL 196.446691 137.277573 \nL 197.011373 138.544086 \nL 197.576055 138.102906 \nL 198.140737 143.359893 \nL 198.70542 146.762735 \nL 199.270102 138.277417 \nL 199.834784 133.239102 \nL 200.399466 134.532046 \nL 200.964148 129.426944 \nL 201.52883 131.401393 \nL 202.093512 130.666309 \nL 202.658194 133.079834 \nL 203.222876 133.92518 \nL 204.35224 119.676809 \nL 204.916922 115.131542 \nL 205.481604 106.886354 \nL 206.046286 116.879321 \nL 206.610969 113.992162 \nL 207.175651 118.463921 \nL 207.740333 121.93157 \nL 208.305015 120.874094 \nL 208.869697 123.499244 \nL 209.434379 134.367563 \nL 209.999061 120.277127 \nL 211.128425 110.708789 \nL 211.693107 103.529472 \nL 212.257789 104.398358 \nL 212.822471 104.031779 \nL 213.951835 107.364158 \nL 214.516518 112.362727 \nL 215.0812 109.66742 \nL 215.645882 108.13459 \nL 216.210564 109.39789 \nL 216.775246 110.341247 \nL 217.339928 110.157476 \nL 217.90461 108.135996 \nL 218.469292 105.024142 \nL 219.033974 102.757634 \nL 219.598656 97.359501 \nL 220.163338 89.636391 \nL 220.72802 94.144904 \nL 221.292702 76.287233 \nL 221.857384 79.07569 \nL 222.422067 77.017455 \nL 222.986749 77.49526 \nL 223.551431 78.487623 \nL 224.116113 80.691205 \nL 224.680795 76.27012 \nL 225.245477 82.060903 \nL 225.810159 80.525083 \nL 226.374841 76.129117 \nL 226.939523 73.562562 \nL 227.504205 75.880676 \nL 228.068887 70.352697 \nL 228.633569 67.448414 \nL 229.198251 67.245709 \nL 229.762933 75.983465 \nL 230.327616 76.551902 \nL 230.892298 75.118489 \nL 231.45698 79.002181 \nL 232.586344 101.691763 \nL 233.151026 96.754451 \nL 233.715708 97.146496 \nL 234.28039 99.363998 \nL 234.845072 108.278918 \nL 235.409754 100.197093 \nL 235.974436 104.252304 \nL 236.539118 102.157316 \nL 237.1038 98.837188 \nL 237.668482 110.389427 \nL 238.233165 99.167976 \nL 238.797847 98.126607 \nL 239.362529 96.705445 \nL 239.927211 97.661054 \nL 241.056575 100.344109 \nL 241.621257 104.313595 \nL 242.750621 97.293512 \nL 243.315303 97.132492 \nL 244.444667 85.948722 \nL 245.009349 91.856726 \nL 245.574031 83.731219 \nL 246.138714 86.332281 \nL 246.703396 79.627002 \nL 247.268078 79.296215 \nL 247.83276 81.881259 \nL 248.397442 86.732811 \nL 248.962124 97.71006 \nL 249.526806 97.109741 \nL 250.091488 96.279732 \nL 250.65617 108.768633 \nL 251.220852 100.478875 \nL 251.785534 104.946265 \nL 252.350216 96.693194 \nL 252.914898 95.149518 \nL 253.47958 100.380864 \nL 254.044263 99.792797 \nL 254.608945 113.739546 \nL 255.173627 97.902946 \nL 255.738309 98.971953 \nL 256.302991 99.11897 \nL 256.867673 104.109661 \nL 257.432355 105.76613 \nL 257.997037 99.8173 \nL 258.561719 108.491103 \nL 259.126401 102.024043 \nL 259.691083 108.228906 \nL 260.255765 116.442441 \nL 260.820447 115.682855 \nL 261.949812 129.196142 \nL 262.514494 142.122198 \nL 263.079176 138.629715 \nL 263.643858 131.278879 \nL 264.20854 125.496221 \nL 264.773222 126.317065 \nL 265.337904 125.986277 \nL 265.902586 121.602905 \nL 266.467268 120.373428 \nL 267.03195 125.595896 \nL 267.596632 119.346021 \nL 268.161314 125.055159 \nL 268.725996 126.983705 \nL 269.290678 120.754932 \nL 269.855361 124.381344 \nL 270.420043 125.030102 \nL 270.984725 123.254216 \nL 271.549407 126.415076 \nL 272.678771 136.415668 \nL 273.243453 121.722792 \nL 273.808135 129.87584 \nL 274.372817 127.52799 \nL 275.502181 112.472989 \nL 276.066863 102.120562 \nL 276.631545 89.636391 \nL 277.196227 73.942356 \nL 277.76091 76.43131 \nL 278.325592 71.2593 \nL 278.890274 80.076949 \nL 279.454956 78.352857 \nL 280.019638 96.607434 \nL 281.149002 144.400122 \nL 281.713684 146.127569 \nL 282.278366 137.269811 \nL 282.843048 125.778003 \nL 283.40773 110.537269 \nL 284.537094 47.17306 \nL 285.101776 34.848158 \nL 285.666459 44.500558 \nL 286.231141 48.594222 \nL 286.795823 51.314031 \nL 287.360505 49.19454 \nL 287.925187 54.721496 \nL 288.489869 57.426631 \nL 289.054551 55.488554 \nL 289.619233 56.858291 \nL 290.183915 59.203929 \nL 290.748597 39.386373 \nL 291.313279 34.95842 \nL 291.877961 22.327233 \nL 292.442643 30.253885 \nL 293.007325 29.06118 \nL 293.572008 28.272219 \nL 294.13669 28.437385 \nL 294.701372 26.30605 \nL 295.266054 17.365418 \nL 295.830736 17.491221 \nL 296.395418 17.966094 \nL 296.9601 25.806629 \nL 297.524782 18.480295 \nL 298.089464 24.704003 \nL 298.654146 23.679716 \nL 299.218828 17.083636 \nL 299.78351 34.291395 \nL 300.348192 32.238611 \nL 300.912874 27.787179 \nL 301.477557 34.358102 \nL 302.042239 38.637075 \nL 302.606921 28.881729 \nL 303.171603 34.664387 \nL 303.736285 42.762558 \nL 304.300967 55.216909 \nL 304.865649 52.99257 \nL 305.430331 55.398565 \nL 305.995013 48.112994 \nL 306.559695 57.464231 \nL 307.124377 70.352697 \nL 307.689059 70.707988 \nL 308.253741 74.371154 \nL 308.818423 59.277437 \nL 309.383105 64.949832 \nL 309.947788 67.571631 \nL 311.641834 48.324691 \nL 312.206516 51.779584 \nL 312.771198 62.32124 \nL 313.33588 56.034094 \nL 313.900562 60.943627 \nL 314.465244 59.902258 \nL 315.029926 59.951264 \nL 315.594608 70.401703 \nL 316.15929 74.77545 \nL 316.723972 81.384269 \nL 317.288654 71.737105 \nL 317.853337 72.239412 \nL 318.982701 76.35588 \nL 319.547383 77.152221 \nL 320.112065 94.205982 \nL 320.676747 94.626308 \nL 321.241429 83.410515 \nL 321.806111 87.185439 \nL 322.370793 76.225273 \nL 322.935475 69.461871 \nL 323.500157 67.547128 \nL 324.064839 68.819648 \nL 324.629521 68.061686 \nL 325.194203 67.583882 \nL 325.758886 68.576245 \nL 326.323568 66.567016 \nL 326.88825 69.393768 \nL 327.452932 69.972904 \nL 328.017614 72.459937 \nL 328.582296 68.612999 \nL 329.146978 68.284186 \nL 330.276342 72.548238 \nL 330.841024 69.752379 \nL 331.405706 76.890646 \nL 331.970388 68.698759 \nL 332.53507 73.185303 \nL 333.099752 72.594702 \nL 334.229117 77.669538 \nL 334.793799 75.74331 \nL 335.358481 85.670769 \nL 335.923163 81.280941 \nL 336.487845 85.519923 \nL 337.052527 90.909 \nL 337.617209 82.885873 \nL 338.181891 83.016147 \nL 338.746573 83.38818 \nL 339.311255 91.837984 \nL 339.875937 95.629246 \nL 340.440619 92.525826 \nL 341.005301 82.33593 \nL 341.569984 78.975542 \nL 342.134666 78.316103 \nL 342.699348 73.28078 \nL 343.26403 77.862802 \nL 343.828712 84.00075 \nL 344.393394 92.912382 \nL 344.958076 85.127878 \nL 345.522758 83.927242 \nL 346.08744 92.478254 \nL 346.652122 85.372906 \nL 347.216804 84.931667 \nL 347.781486 83.669962 \nL 348.346168 83.770884 \nL 348.91085 93.271453 \nL 349.475533 74.654465 \nL 350.040215 71.70035 \nL 350.604897 72.864233 \nL 351.169579 72.080144 \nL 351.734261 73.060255 \nL 352.298943 75.836401 \nL 352.863625 73.991361 \nL 353.428307 81.677244 \nL 353.992989 78.695896 \nL 354.557671 79.048839 \nL 355.122353 82.310058 \nL 355.687035 81.991521 \nL 355.687035 81.991521 \n\" style=\"fill:none;stroke:#4c72b0;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_13\">\n    <path clip-path=\"url(#pcada54abc7)\" d=\"M 356.251717 88.442526 \nL 356.816399 88.994677 \nL 357.381082 89.054498 \nL 357.945764 89.019203 \nL 358.510446 88.922293 \nL 359.075128 88.795472 \nL 359.63981 88.676427 \nL 360.204492 88.58191 \nL 360.769174 88.516106 \nL 361.333856 88.47483 \nL 361.898538 88.452098 \nL 362.46322 88.440732 \nL 363.027902 88.437142 \nL 363.592584 88.437741 \nL 364.157266 88.440133 \nL 364.721948 88.443125 \nL 365.286631 88.446116 \nL 365.851313 88.449107 \nL 366.415995 88.4515 \nL 366.980677 88.452696 \nL 367.545359 88.454491 \nL 368.110041 88.455089 \nL 368.674723 88.456285 \nL 369.239405 88.456285 \nL 369.804087 88.456285 \nL 370.368769 88.456883 \nL 370.933451 88.456883 \nL 371.498133 88.456883 \nL 372.062815 88.456883 \nL 372.627497 88.456883 \nL 373.19218 88.456883 \nL 373.756862 88.456883 \nL 374.321544 88.456883 \nL 374.886226 88.456883 \nL 375.450908 88.456883 \nL 376.01559 88.456883 \nL 376.580272 88.456883 \nL 377.144954 88.456883 \nL 377.709636 88.456883 \nL 378.274318 88.456883 \n\" style=\"fill:none;stroke:#dd8452;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 58.6925 224.64 \nL 58.6925 7.2 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 393.4925 224.64 \nL 393.4925 7.2 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 58.6925 224.64 \nL 393.4925 224.64 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 58.6925 7.2 \nL 393.4925 7.2 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pcada54abc7\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"58.6925\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "# For example, if we just want to predict the next timestep in the dataset we can prepare it as such:\n",
    "\n",
    "# 1. get the [length] last points from the data set since that's what we care about\n",
    "length = LENGTH\n",
    "whole_df = pd.read_csv('../../data/ETH.csv')\n",
    "# most_recent_period = np.array(recent_history)\n",
    "recent_history = pd.DataFrame({'price': whole_df[[\"high_price\",\"low_price\"]].mean(axis=1)}).tail(length)\n",
    "recent_history = recent_history.set_index(pd.DatetimeIndex(pd.to_datetime(whole_df['begins_at'].tail(length))))\n",
    "\n",
    "# 2. convert to numpy array \n",
    "most_recent_period = np.array(recent_history)\n",
    "\n",
    "# 3. normalize data\n",
    "scaler = MinMaxScaler()\n",
    "most_recent_period_scaled = scaler.fit_transform(most_recent_period)\n",
    "\n",
    "# 4. reshape to the 3D tensor we expected (1, length, 1)\n",
    "most_recent_period_scaled_shaped = most_recent_period_scaled.reshape((1, length, 1))\n",
    "\n",
    "# 5. Predict\n",
    "prediction = model.predict(most_recent_period_scaled_shaped)\n",
    "# print(prediction[0])\n",
    "# 6. Un-normalize the data\n",
    "result = scaler.inverse_transform(prediction[0])\n",
    "recent_history_unscaled = scaler.inverse_transform(most_recent_period_scaled)\n",
    "recent_history.price = recent_history_unscaled\n",
    "\n",
    "# print(result)\n",
    "pred_df = pd.DataFrame(result)\n",
    "# pred_df = pred_df.set_index(pd.DatetimeIndex(pd.date_range(recent_history.index[-1], periods=len(result[0]), freq=\"15s\")))\n",
    "\n",
    "plt.plot(recent_history_unscaled)\n",
    "plt.plot(np.arange(length, length+LOOK_AHEAD_LENGTH),result)\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "# Prediction Success Evaluation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Assets written to: encoder-decoder-40back-10forward/assets\n"
     ]
    }
   ],
   "source": [
    "# model.save(\"encoder-decoder-40back-10forward\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.load_model(\"../../models/5kepochs500back20forward_encodedecode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Target 0 [[0.64350943]\n",
      " [0.63941292]\n",
      " [0.64156827]\n",
      " [0.64050001]\n",
      " [0.63840887]\n",
      " [0.63017568]\n",
      " [0.62040668]\n",
      " [0.61879647]\n",
      " [0.61688734]\n",
      " [0.60380268]]\n",
      "Target 0 reshape [[0.64350943]\n",
      " [0.63941292]\n",
      " [0.64156827]\n",
      " ...\n",
      " [0.84695632]\n",
      " [0.85132058]\n",
      " [0.84755875]]\n",
      "Target 0 reshape size (220650, 1)\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_10 (LSTM)               (None, 200)               161600    \n",
      "_________________________________________________________________\n",
      "repeat_vector_5 (RepeatVecto (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 10, 200)           320800    \n",
      "_________________________________________________________________\n",
      "time_distributed_10 (TimeDis (None, 10, 100)           20100     \n",
      "_________________________________________________________________\n",
      "time_distributed_11 (TimeDis (None, 10, 1)             101       \n",
      "=================================================================\n",
      "Total params: 502,601\n",
      "Trainable params: 502,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Target 0 [[0.64350943]\n",
      " [0.63941292]\n",
      " [0.64156827]\n",
      " [0.64050001]\n",
      " [0.63840887]\n",
      " [0.63017568]\n",
      " [0.62040668]\n",
      " [0.61879647]\n",
      " [0.61688734]\n",
      " [0.60380268]]\n",
      "Target 0 reshape [[0.64350943]\n",
      " [0.63941292]\n",
      " [0.64156827]\n",
      " ...\n",
      " [0.84695632]\n",
      " [0.85132058]\n",
      " [0.84755875]]\n",
      "Target 0 reshape size (220650, 1)\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_12 (LSTM)               (None, 200)               161600    \n",
      "_________________________________________________________________\n",
      "repeat_vector_6 (RepeatVecto (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "lstm_13 (LSTM)               (None, 10, 200)           320800    \n",
      "_________________________________________________________________\n",
      "time_distributed_12 (TimeDis (None, 10, 100)           20100     \n",
      "_________________________________________________________________\n",
      "time_distributed_13 (TimeDis (None, 10, 1)             101       \n",
      "=================================================================\n",
      "Total params: 502,601\n",
      "Trainable params: 502,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Target 0 [[0.64350943]\n",
      " [0.63941292]\n",
      " [0.64156827]\n",
      " [0.64050001]\n",
      " [0.63840887]\n",
      " [0.63017568]\n",
      " [0.62040668]\n",
      " [0.61879647]\n",
      " [0.61688734]\n",
      " [0.60380268]]\n",
      "Target 0 reshape [[0.64350943]\n",
      " [0.63941292]\n",
      " [0.64156827]\n",
      " ...\n",
      " [0.84695632]\n",
      " [0.85132058]\n",
      " [0.84755875]]\n",
      "Target 0 reshape size (220650, 1)\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_14 (LSTM)               (None, 200)               161600    \n",
      "_________________________________________________________________\n",
      "repeat_vector_7 (RepeatVecto (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "lstm_15 (LSTM)               (None, 10, 200)           320800    \n",
      "_________________________________________________________________\n",
      "time_distributed_14 (TimeDis (None, 10, 100)           20100     \n",
      "_________________________________________________________________\n",
      "time_distributed_15 (TimeDis (None, 10, 1)             101       \n",
      "=================================================================\n",
      "Total params: 502,601\n",
      "Trainable params: 502,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Target 0 [[0.64350943]\n",
      " [0.63941292]\n",
      " [0.64156827]\n",
      " [0.64050001]\n",
      " [0.63840887]\n",
      " [0.63017568]\n",
      " [0.62040668]\n",
      " [0.61879647]\n",
      " [0.61688734]\n",
      " [0.60380268]]\n",
      "Target 0 reshape [[0.64350943]\n",
      " [0.63941292]\n",
      " [0.64156827]\n",
      " ...\n",
      " [0.84695632]\n",
      " [0.85132058]\n",
      " [0.84755875]]\n",
      "Target 0 reshape size (220650, 1)\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_16 (LSTM)               (None, 200)               161600    \n",
      "_________________________________________________________________\n",
      "repeat_vector_8 (RepeatVecto (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "lstm_17 (LSTM)               (None, 10, 200)           320800    \n",
      "_________________________________________________________________\n",
      "time_distributed_16 (TimeDis (None, 10, 100)           20100     \n",
      "_________________________________________________________________\n",
      "time_distributed_17 (TimeDis (None, 10, 1)             101       \n",
      "=================================================================\n",
      "Total params: 502,601\n",
      "Trainable params: 502,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Target 0 [[0.64350943]\n",
      " [0.63941292]\n",
      " [0.64156827]\n",
      " [0.64050001]\n",
      " [0.63840887]\n",
      " [0.63017568]\n",
      " [0.62040668]\n",
      " [0.61879647]\n",
      " [0.61688734]\n",
      " [0.60380268]]\n",
      "Target 0 reshape [[0.64350943]\n",
      " [0.63941292]\n",
      " [0.64156827]\n",
      " ...\n",
      " [0.84695632]\n",
      " [0.85132058]\n",
      " [0.84755875]]\n",
      "Target 0 reshape size (220650, 1)\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_18 (LSTM)               (None, 200)               161600    \n",
      "_________________________________________________________________\n",
      "repeat_vector_9 (RepeatVecto (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "lstm_19 (LSTM)               (None, 10, 200)           320800    \n",
      "_________________________________________________________________\n",
      "time_distributed_18 (TimeDis (None, 10, 100)           20100     \n",
      "_________________________________________________________________\n",
      "time_distributed_19 (TimeDis (None, 10, 1)             101       \n",
      "=================================================================\n",
      "Total params: 502,601\n",
      "Trainable params: 502,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Target 0 [[0.64350943]\n",
      " [0.63941292]\n",
      " [0.64156827]\n",
      " [0.64050001]\n",
      " [0.63840887]\n",
      " [0.63017568]\n",
      " [0.62040668]\n",
      " [0.61879647]\n",
      " [0.61688734]\n",
      " [0.60380268]]\n",
      "Target 0 reshape [[0.64350943]\n",
      " [0.63941292]\n",
      " [0.64156827]\n",
      " ...\n",
      " [0.84695632]\n",
      " [0.85132058]\n",
      " [0.84755875]]\n",
      "Target 0 reshape size (220650, 1)\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_20 (LSTM)               (None, 200)               161600    \n",
      "_________________________________________________________________\n",
      "repeat_vector_10 (RepeatVect (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "lstm_21 (LSTM)               (None, 10, 200)           320800    \n",
      "_________________________________________________________________\n",
      "time_distributed_20 (TimeDis (None, 10, 100)           20100     \n",
      "_________________________________________________________________\n",
      "time_distributed_21 (TimeDis (None, 10, 1)             101       \n",
      "=================================================================\n",
      "Total params: 502,601\n",
      "Trainable params: 502,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Target 0 [[0.64350943]\n",
      " [0.63941292]\n",
      " [0.64156827]\n",
      " [0.64050001]\n",
      " [0.63840887]\n",
      " [0.63017568]\n",
      " [0.62040668]\n",
      " [0.61879647]\n",
      " [0.61688734]\n",
      " [0.60380268]]\n",
      "Target 0 reshape [[0.64350943]\n",
      " [0.63941292]\n",
      " [0.64156827]\n",
      " ...\n",
      " [0.84695632]\n",
      " [0.85132058]\n",
      " [0.84755875]]\n",
      "Target 0 reshape size (220650, 1)\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_22 (LSTM)               (None, 200)               161600    \n",
      "_________________________________________________________________\n",
      "repeat_vector_11 (RepeatVect (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "lstm_23 (LSTM)               (None, 10, 200)           320800    \n",
      "_________________________________________________________________\n",
      "time_distributed_22 (TimeDis (None, 10, 100)           20100     \n",
      "_________________________________________________________________\n",
      "time_distributed_23 (TimeDis (None, 10, 1)             101       \n",
      "=================================================================\n",
      "Total params: 502,601\n",
      "Trainable params: 502,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Target 0 [[0.64350943]\n",
      " [0.63941292]\n",
      " [0.64156827]\n",
      " [0.64050001]\n",
      " [0.63840887]\n",
      " [0.63017568]\n",
      " [0.62040668]\n",
      " [0.61879647]\n",
      " [0.61688734]\n",
      " [0.60380268]]\n",
      "Target 0 reshape [[0.64350943]\n",
      " [0.63941292]\n",
      " [0.64156827]\n",
      " ...\n",
      " [0.84695632]\n",
      " [0.85132058]\n",
      " [0.84755875]]\n",
      "Target 0 reshape size (220650, 1)\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_24 (LSTM)               (None, 200)               161600    \n",
      "_________________________________________________________________\n",
      "repeat_vector_12 (RepeatVect (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "lstm_25 (LSTM)               (None, 10, 200)           320800    \n",
      "_________________________________________________________________\n",
      "time_distributed_24 (TimeDis (None, 10, 100)           20100     \n",
      "_________________________________________________________________\n",
      "time_distributed_25 (TimeDis (None, 10, 1)             101       \n",
      "=================================================================\n",
      "Total params: 502,601\n",
      "Trainable params: 502,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Target 0 [[0.64350943]\n",
      " [0.63941292]\n",
      " [0.64156827]\n",
      " [0.64050001]\n",
      " [0.63840887]\n",
      " [0.63017568]\n",
      " [0.62040668]\n",
      " [0.61879647]\n",
      " [0.61688734]\n",
      " [0.60380268]]\n",
      "Target 0 reshape [[0.64350943]\n",
      " [0.63941292]\n",
      " [0.64156827]\n",
      " ...\n",
      " [0.84695632]\n",
      " [0.85132058]\n",
      " [0.84755875]]\n",
      "Target 0 reshape size (220650, 1)\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_26 (LSTM)               (None, 200)               161600    \n",
      "_________________________________________________________________\n",
      "repeat_vector_13 (RepeatVect (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "lstm_27 (LSTM)               (None, 10, 200)           320800    \n",
      "_________________________________________________________________\n",
      "time_distributed_26 (TimeDis (None, 10, 100)           20100     \n",
      "_________________________________________________________________\n",
      "time_distributed_27 (TimeDis (None, 10, 1)             101       \n",
      "=================================================================\n",
      "Total params: 502,601\n",
      "Trainable params: 502,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Target 0 [[0.64350943]\n",
      " [0.63941292]\n",
      " [0.64156827]\n",
      " [0.64050001]\n",
      " [0.63840887]\n",
      " [0.63017568]\n",
      " [0.62040668]\n",
      " [0.61879647]\n",
      " [0.61688734]\n",
      " [0.60380268]]\n",
      "Target 0 reshape [[0.64350943]\n",
      " [0.63941292]\n",
      " [0.64156827]\n",
      " ...\n",
      " [0.84695632]\n",
      " [0.85132058]\n",
      " [0.84755875]]\n",
      "Target 0 reshape size (220650, 1)\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_28 (LSTM)               (None, 200)               161600    \n",
      "_________________________________________________________________\n",
      "repeat_vector_14 (RepeatVect (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "lstm_29 (LSTM)               (None, 10, 200)           320800    \n",
      "_________________________________________________________________\n",
      "time_distributed_28 (TimeDis (None, 10, 100)           20100     \n",
      "_________________________________________________________________\n",
      "time_distributed_29 (TimeDis (None, 10, 1)             101       \n",
      "=================================================================\n",
      "Total params: 502,601\n",
      "Trainable params: 502,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Target 0 [[0.64350943]\n",
      " [0.63941292]\n",
      " [0.64156827]\n",
      " [0.64050001]\n",
      " [0.63840887]\n",
      " [0.63017568]\n",
      " [0.62040668]\n",
      " [0.61879647]\n",
      " [0.61688734]\n",
      " [0.60380268]]\n",
      "Target 0 reshape [[0.64350943]\n",
      " [0.63941292]\n",
      " [0.64156827]\n",
      " ...\n",
      " [0.84695632]\n",
      " [0.85132058]\n",
      " [0.84755875]]\n",
      "Target 0 reshape size (220650, 1)\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_30 (LSTM)               (None, 200)               161600    \n",
      "_________________________________________________________________\n",
      "repeat_vector_15 (RepeatVect (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "lstm_31 (LSTM)               (None, 10, 200)           320800    \n",
      "_________________________________________________________________\n",
      "time_distributed_30 (TimeDis (None, 10, 100)           20100     \n",
      "_________________________________________________________________\n",
      "time_distributed_31 (TimeDis (None, 10, 1)             101       \n",
      "=================================================================\n",
      "Total params: 502,601\n",
      "Trainable params: 502,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# profits = []\n",
    "# for length in np.arange(5, 360, 5):\n",
    "#     for sub in np.arange(10, 480, 5):\n",
    "#         try:\n",
    "#             LENGTH = length\n",
    "#             SUBSAMPLING = sub\n",
    "#             model = trainModel(datasets, LENGTH, quiet=True)\n",
    "#             profit = testModel(model, \"../../data/MorningTest.csv\", quiet=True)\n",
    "#             profits.append((profit, length, sub))\n",
    "#             print(sorted(profits, key=lambda tup: -tup[0])[0:20])\n",
    "#         except:\n",
    "#             pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"FINAL RESULTS\")\n",
    "# sorted(profits, key=lambda tup: tup[0])[0:20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}